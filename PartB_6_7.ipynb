{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "56a9bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels with 0: 26520 and 200.3021148036254 %\n",
      "Number of labels with 1: 13200 and 99.69788519637463 %\n",
      "Twitter example of label 0: \n",
      " Amazon is investigating Chinese employees who are selling internal data to third-party sellers looking for an edge in the competitive marketplace. URL #Amazon #MAGA #KAG #CHINA #TCOT\n",
      "Twitter example of label 1: \n",
      " @USER She should ask a few native Americans what their take on this is.\n",
      "Random baseline: {0: {'precision': 0.67, 'recall': 0.5, 'f1-score': 0.58}, 1: {'precision': 0.34, 'recall': 0.51, 'f1-score': 0.41}, 'macro_precision': 0.5, 'weighted_precision': 0.56, 'macro_recall': 0.5, 'weighted_recall': 0.5, 'macro_f1-score': 0.5, 'weighted_f1-score': 0.52} \n",
      "\n",
      "Majority baseline: {0: {'precision': 0.67, 'recall': 1.0, 'f1-score': 0.8}, 1: {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0}, 'macro_precision': 0.34, 'weighted_precision': 0.45, 'macro_recall': 0.5, 'weighted_recall': 0.67, 'macro_f1-score': 0.4, 'weighted_f1-score': 0.53}\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "#Assignment 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import nltk\n",
    "import csv\n",
    "import torch\n",
    "from collections import defaultdict, Counter\n",
    "import random\n",
    "import sklearn.metrics as sk\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from random import seed\n",
    "from random import randrange\n",
    "\n",
    "\n",
    "#Task 1: Class distribution\n",
    "train_file = 'olid-train.csv'\n",
    "df = pd.read_csv(train_file) \n",
    "count_lab0 = 0\n",
    "count_lab1 = 0\n",
    "for item in df:\n",
    "    for i in df.labels:\n",
    "        if i==0:\n",
    "            count_lab0 += 1\n",
    "        if i==1:\n",
    "            count_lab1 += 1\n",
    "            #print()\n",
    "tot_labels=len(df.labels)\n",
    "print('Number of labels with 0:', count_lab0, 'and', (count_lab0*100/tot_labels), '%')   # 0 = NOT (non-offensive messages)\n",
    "print('Number of labels with 1:', count_lab1, 'and', (count_lab1*100/tot_labels), '%')   # 1 = OFF (offensive messages)\n",
    "print('Twitter example of label 0: \\n', df.loc[df['labels']==0, 'text'].iloc[0])\n",
    "print('Twitter example of label 1: \\n', df.loc[df['labels']==1, 'text'].iloc[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "#Task 2: Baselines\n",
    "#Definitions:\n",
    "#precision = True Positives / (True Positives + False Positives)\n",
    "#recall = True Positives / (True Positives + False Negatives)\n",
    "#F1 = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "#macro-average = does not take class imbalance into account\n",
    "#weighted average = average over classes, weighted by class size (support)\n",
    "\n",
    "test_file='olid-test.csv'\n",
    "df2 = pd.read_csv(test_file)\n",
    "labels = df[\"labels\"]\n",
    "class_count = labels.value_counts()\n",
    "class_freq = class_count / sum(class_count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#2.1: Random baseline that randomly assigns one of the 2 classification labels\n",
    "prf1_list = ['precision', 'recall', 'f1-score']\n",
    "random_base = {0: {'precision': [], 'recall': [], 'f1-score': []},\n",
    "                  1: {'precision': [], 'recall': [], 'f1-score': []}}\n",
    "random.seed(2)   #seed is randomly chosen \n",
    "random_labels = np.random.randint(0, 2, len(labels))\n",
    "temp_result = sk.classification_report(labels, random_labels, output_dict=True)\n",
    "for i in range(2):\n",
    "    for m in prf1_list:\n",
    "        random_base[i][m].append(temp_result[str(i)][m])\n",
    "\n",
    "#2.2: Majority baseline that always assigns the majority class\n",
    "majority_base = {0: {'precision': [], 'recall': [], 'f1-score': []},\n",
    "                    1: {'precision': [], 'recall': [], 'f1-score': []}}\n",
    "major_labels = np.full_like(labels, np.argmax(class_count))\n",
    "temp_result = sk.classification_report(labels, major_labels, output_dict=True, zero_division=0)\n",
    "for i in range(2):\n",
    "    for m in prf1_list:\n",
    "        majority_base[i][m].append(temp_result[str(i)][m])\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "# Create dictionary with results\n",
    "for m in prf1_list:\n",
    "    results_random = []\n",
    "    results_major = []\n",
    "    for i in range(2):\n",
    "        random_base[i][m] = round(np.mean(random_base[i][m]), 2)\n",
    "        results_random.append(random_base[i][m])\n",
    "        majority_base[i][m] = round(np.mean(majority_base[i][m]), 2)\n",
    "        results_major.append(majority_base[i][m])\n",
    "    random_base['macro_' + m] = round(np.mean(results_random), 2)\n",
    "    random_base['weighted_' + m] = round(np.average(results_random, weights=class_freq.values), 2)\n",
    "    majority_base['macro_' + m] = round(np.mean(results_major), 2)\n",
    "    majority_base['weighted_' + m] = round(np.average(results_major, weights=class_freq.values), 2)\n",
    "\n",
    "print('Random baseline:', random_base, '\\n')\n",
    "print('Majority baseline:', majority_base)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0297cf84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c15c2345-51f3-413b-bbd5-9434adbb5cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213e09e-e97d-4c45-847a-ccaad995eda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-cased',num_labels = 5)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fee7f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28756b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "8d160f13-c3b8-4cc2-8bf0-f01b8330e51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89200</td>\n",
       "      <td>@USER @USER Who the hell does he think he is?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71294</td>\n",
       "      <td>#BREAKING. #Greece: Molotov cocktails fly afte...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55633</td>\n",
       "      <td>#OrrinHatch I can’t believe this sexist , clue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16856</td>\n",
       "      <td>@USER @USER I'll use that one the next time im...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26072</td>\n",
       "      <td>0-1 lost my acca on the first fucking fight cba</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>45518</td>\n",
       "      <td>@USER He is obviously getting suspended. He is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>51610</td>\n",
       "      <td>#Canada - EXCLUSIVE: #Trudeau #Liberals leave ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>26758</td>\n",
       "      <td>@USER @USER ...than why did you show us how ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>30718</td>\n",
       "      <td>@USER @USER @USER You have yet to answer what ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>82558</td>\n",
       "      <td>#MAGA  ... got any ideas how she could have do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  labels\n",
       "0   89200      @USER @USER Who the hell does he think he is?       1\n",
       "1   71294  #BREAKING. #Greece: Molotov cocktails fly afte...       1\n",
       "2   55633  #OrrinHatch I can’t believe this sexist , clue...       1\n",
       "3   16856  @USER @USER I'll use that one the next time im...       1\n",
       "4   26072    0-1 lost my acca on the first fucking fight cba       1\n",
       "..    ...                                                ...     ...\n",
       "95  45518  @USER He is obviously getting suspended. He is...       0\n",
       "96  51610  #Canada - EXCLUSIVE: #Trudeau #Liberals leave ...       0\n",
       "97  26758  @USER @USER ...than why did you show us how ho...       0\n",
       "98  30718  @USER @USER @USER You have yet to answer what ...       0\n",
       "99  82558  #MAGA  ... got any ideas how she could have do...       0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Part B: Error analysis with checklist\n",
    "\n",
    "#New train set - subset 100 instances\n",
    "train_set='olid-subset-diagnostic-tests.csv'\n",
    "subset = pd.read_csv(train_set)\n",
    "labels = df[\"labels\"]\n",
    "class_count = labels.value_counts()\n",
    "class_freq = class_count / sum(class_count)\n",
    "\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "f3668e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perturbations\n",
    "\n",
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5762e66c-5acd-4bb9-a73b-13471e7a5cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jupyter nbextension install --py --sys-prefix checklist.viewer\n",
    "# jupyter nbextension enable --py --sys-prefix checklist.viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "f15a0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ada69f7-8dac-41d5-bd86-160724098c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbedf381",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "78dbb78c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load SA  \n",
    "\n",
    "import checklist\n",
    "from checklist.test_suite import TestSuite\n",
    "# suite_path = 'release_data/sentiment/sentiment_suite.pkl'\n",
    "#suite = TestSuite.from_file(suite_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "09f26f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = 'release_data/sentiment/predictions/bert'\n",
    "#suite.run_from_file(pred_path, overwrite=True)\n",
    "#suite.summary() # or suite.visual_summary_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "58519d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perturbations\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "pdataset = list(nlp.pipe(subset))\n",
    "ret = Perturb.perturb(pdataset, Perturb.change_names, n=2)\n",
    "ret.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b959c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ae836907-4f98-45c7-9a97-de21001d4809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MunchWithAdd({'data': []})"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q6. Adding negations\n",
    "\n",
    "#neg = Perturb.add_negation(subset['text'])\n",
    "#neg.subset\n",
    "\n",
    "negated_text = Perturb.perturb(pdataset, Perturb.add_negation, keep_original=False)\n",
    "negated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "7892d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_text=subset['text']\n",
    "# neg_list=[]\n",
    "# for i in range(0,len(subset)):\n",
    "  #  neg_list.append(Perturb.add_negation(all_text1[i]))\n",
    "    \n",
    "#subset_text=list(nlp.pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48b4972-042c-48de-904c-909f4d686e8b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3ac31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef00685-01a5-4de7-abdd-7d2a5cdbc96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c795ed-68bb-4a8b-a929-5db8434499e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89487285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08c5903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e8330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Negated examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9ec8e883-f94f-426c-94a9-e51fb107f047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4de4cfa4dbd4fb4904a9ab22af82735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bbb38bcf4c84b9b87a8f10c23c40f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f103d0adf14b2d812b06dcf2b13797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598c5e8a85d54d0d9f6e4f86688807bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33fdd67acbb45ab9040a718802d5a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['I hate work',\n",
       " 'I hate her',\n",
       " 'I hate politicians',\n",
       " 'I hate him',\n",
       " 'I hate school',\n",
       " 'I hate you',\n",
       " 'I hate inequality',\n",
       " 'I hate change',\n",
       " 'I hate hate',\n",
       " 'I hate capitalism']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From lexicon -> ‘I hate {nationality}’, ‘I don’t hate {nationality}’, ‘I hate {religion}’, ‘I don’t hate {religion}’ \n",
    "\n",
    "editor = Editor(language='English')\n",
    "ret = editor.template('I hate {mask}', remove_duplicates=True)\n",
    "list(np.random.choice(ret.data, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ba54240d-399f-499a-a2fe-2c835dce5e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't hate Russians\",\n",
       " \"I don't hate Jews\",\n",
       " \"I don't hate bullies\",\n",
       " \"I don't hate God\",\n",
       " \"I don't hate abortion\",\n",
       " \"I don't hate Trump\",\n",
       " \"I don't hate work\",\n",
       " \"I don't hate Americans\",\n",
       " \"I don't hate racism\",\n",
       " \"I don't hate you\"]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = editor.template('I don\\'t hate {mask}', remove_duplicates=True)\n",
    "list(np.random.choice(ret.data, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "195f4e67-d37e-43a1-bcda-4ac4e7d523a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I hate Turks and Caicos Island',\n",
       " 'I hate Rwandan',\n",
       " 'I hate Jamaican',\n",
       " 'I hate Kenyan',\n",
       " 'I hate Saint Lucian',\n",
       " 'I hate British',\n",
       " 'I hate Serbian',\n",
       " 'I hate Bissau-Guinean',\n",
       " 'I hate Ivorian',\n",
       " 'I hate Gambian']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = editor.template('I hate {nationality}', remove_duplicates=True)\n",
    "list(np.random.choice(ret.data, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6f286c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't hate Djiboutian\",\n",
       " \"I don't hate Fijian\",\n",
       " \"I don't hate Basotho\",\n",
       " \"I don't hate Cameroonian\",\n",
       " \"I don't hate Somali\",\n",
       " \"I don't hate Togolese\",\n",
       " \"I don't hate Azerbaijani\",\n",
       " \"I don't hate Gabonese\",\n",
       " \"I don't hate Qatari\",\n",
       " \"I don't hate Bangladeshi\"]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = editor.template('I don\\'t hate {nationality}', remove_duplicates=True)\n",
    "list(np.random.choice(ret.data, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "938a53de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I hate Judaism',\n",
       " 'I hate Agnosticism',\n",
       " 'I hate Buddhism',\n",
       " 'I hate Christianity',\n",
       " \"I hate Baha'i\",\n",
       " 'I hate Agnosticism',\n",
       " 'I hate Agnosticism',\n",
       " 'I hate Sikhism',\n",
       " 'I hate Zoroastrianism',\n",
       " 'I hate Hinduism']"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = editor.template('I hate {religion}', remove_duplicates=True)\n",
    "list(np.random.choice(ret.data, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "ad576cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I don't hate Atheism\",\n",
       " \"I don't hate Islam\",\n",
       " \"I don't hate Christianity\",\n",
       " \"I don't hate Agnosticism\",\n",
       " \"I don't hate Confucianism\",\n",
       " \"I don't hate Shintoism\",\n",
       " \"I don't hate Atheism\",\n",
       " \"I don't hate Judaism\",\n",
       " \"I don't hate Shintoism\",\n",
       " \"I don't hate Taoism\"]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = editor.template('I don\\'t hate {religion}', remove_duplicates=True)\n",
    "list(np.random.choice(ret.data, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd057d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5702d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
